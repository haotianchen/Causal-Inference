---
title: 'Pol Sci 200C Section: Observational Studies'
author: 'Haotian (Barney) Chen'
date: "April 18, 2025 + April 25, 2025"  
output:
  html_document:
    math_method: mathjax
    mathjax: "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE, fig.align = 'center')
```

\newcommand{\y}{\mathbf{y}}
\newcommand{\X}{\mathbf{X}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\V}{\mathbb{V}}
\newcommand{\independent}{\perp\!\!\!\perp}


> The First Commandment of Causal Inference: a result is causal if you can support the assumption(s) that make it causal, not because you performed some procedure.


## Selection on Observables (SOO)

***
- Recall that random assignment guarantees **ignorability**: $\E[Y_{1i}|D_i=1] = \E[Y_{1i}|D_i=0]$ and $\E[Y_{0i}|D_i=1] = \E[Y_{0i}|D_i=0]$. In observational studies, however, it is not always met. 
  
- Goal of SOO: once we condition on some **pre-treatment** observed covariates, treatment is as-if random assignment. We will discuss estimation strategies including stratification, matching, weighting, and regression. 

-  Here we invoke the **<span style="color:red;">conditional ignorability</span>** (selection on observables; conditional exogeneity; conditional exchangeability; conditional independence) assumption: $$\{ Y_{0i}, Y_{1i} \} \independent D_i|X_i=x \; \text{ for any } \; x \in \chi,$$ which means that among units with same values of covariates $X_i$, $D_i$ is "as-if" randomly assigned. In other words, the conditional distribution of potential outcomes is identical across levels of the treatment once we condition on the covariates $X$. 
 
- Similarly, we have weaker versions of the conditional ignorability: $\{Y_{1i} \} \independent D_i|X_i=x \; \text{ for any } \; x \in \chi$ or $\{ Y_{0i} \} \independent D_i|X_i=x \; \text{ for any } \; x \in \chi$. 

- We also need the **<span style="color:red;">common support (positivity)</span>** assumption: $$0<\Pr(D_i=1|X_i=x)<1 \; \text{ for any } \; x \in \chi,$$ which means that "with any value of $X_i$, unit could have received either treatment or  control."
 
- Identification of $ATE$ under conditional ignorability:
 
$$
 \begin{align*}
 \tau_{ATE} &= \E[Y_{1i} - Y_{0i}] \\
 &= \E_X[\E[Y_{1i} - Y_{0i} | X_i]]    &\text{(law of iterated expectation)} \\
 &= \int \underbrace{\E[Y_{1i} - Y_{0i}|X_i=x]}_{\tau(x):\text{ATE among subgroup }X_i=x} P(x)dx  &\text{(definition of } \E) \\
 &= \int (\E[Y_{1i}|X_i=x] - \E[Y_{0i}|X_i=x] ) P(x)dx  &\text{(linearity of }\E) \\
 &= \int (\E[Y_{1i}|X_i=x, \color{black}{D_i=1}] - \E[Y_{0i}|X_i=x, \color{black}{D_i=0}]) P(x)dx  &\text{(conditional ignorability + common support)} \\
 &= \int (\E[Y_i|X_i=x, D_i=1] - \E[Y_i|X_i=x, D_i=0]) P(x)dx  &\text{(consistency +  SUTVA)}\\
 &= \E_X [ \overbrace{ \underbrace{\E[Y_{i}|X_i=x, D_i=1]}_{\text{weighted mean of treated w/ }X_i=x} - \underbrace{\E[Y_i|X_i=x, D_i=0]}_{\text{weighted mean of control w/ }X_i=x} }^{\text{Conditional Expectation Function; let's call it } \hat{\tau}(x)} ]\\
 &= \E_X [\hat{\tau}(x)].
 \end{align*}
$$

- The identification result for ATT ($\E[Y_{1i}-Y_{0i}|D_i=1]$) is similar, but replace $f(x)$ with $f(x|D_i=1)$: for ATT, we now take expectation with respect to the distribution of $X_i$ given $D_i=1$ (instead of the marginal distribution of $X$). 
 
$$
 \begin{align*}
 \tau_{ATT} &= \E[Y_{1i} - Y_{0i} | D_i=1] \\
 &= \E_X[\E[Y_{1i} - Y_{0i} | X_i, D_i=1]]    &\text{(law of iterated expectation)} \\
 &= \int \underbrace{\E[Y_{1i} - Y_{0i}|X_i=x, D_i=1]}_{\tau(x):\text{ATT among subgroup }X_i=x} P(x|D_i=1)dx  &\text{(definition of } \E) \\
 &= \int (\E[Y_{1i}|X_i=x, D_i=1] - \E[Y_{0i}|X_i=x, D_i=1] ) P(x|D_i=1)dx  &\text{(linearity of }\E) \\
 &= \int (\E[Y_{1i}|X_i=x, D_i=1] - \E[Y_{0i}|X_i=x, D_i=0]) P(x|D_i=1)dx  &\text{(weaker conditional ignorability)} \\
 &= \int (\E[Y_i|X_i=x, D_i=1] - \E[Y_i|X_i=x, D_i=0]) P(x|D_i=1)dx  &\text{(consistency +  SUTVA)} \\
 \end{align*}
$$

 <br>

## Subclassification/Stratification

***

- In subclassification, we 1) partition the data by covariates X, 2) calculate the difference in means of $Y_i$ between the treated and untreated within each stratum, and 3) calculate the weighted average of (2), with weights equal to the proportions of units in the strata.

- We can write down the subclassification estimators: 
$$
\hat \tau_{ATE} = \sum_{j=1}^{M}\{\overline Y_{1j} - \overline Y_{0j}\}\frac{n_j}{n}
$$
$$
\hat \tau_{ATT} = \sum_{j=1}^{M}\{\overline Y_{1j} - \overline Y_{0j}\}\frac{n_{1j}}{n_1}
$$
where $M$ is the number of strata. 

- It only works if the dimension of $X$ is small. 


```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(haven)
library(estimatr)

# we gonna use the titanic example from Scott Cunningham's Mixtape

titanic <- read_dta("https://github.com/scunning1975/mixtape/raw/master/titanic.dta") %>% 
  mutate(d = case_when(class == 1 ~ 1, TRUE ~ 0)) 
# `class` is the treatment, indicating if the passenger is in first class or not

sdo <- titanic %>%
  summarise(sdo = mean(survived[d == 1]) - mean(survived[d == 0])) %>%
  pull(sdo) # DIM

# subclassification:
# stratify the data into four groups: younger males, younger females, older males, older females.
titanic <- titanic %>% mutate(s = case_when(sex == 0 & age == 1 ~ 1,
                                            sex == 0 & age == 0 ~ 2,
                                            sex == 1 & age == 1 ~ 3,
                                            sex == 1 & age == 0 ~ 4))

wate <- titanic %>%
  group_by(s, d) %>%
  summarise(n = n(), ey = mean(survived), .groups = "drop") %>%
  pivot_wider(names_from = d, values_from = c(n, ey), names_sep = "_") %>%
  mutate(diff = ey_1 - ey_0, wt = n_0 / sum(n_0)) %>% # weight = # untreated in stratum / total # of untreated
  summarise(wate = sum(diff * wt)) %>% # weighted average of the differences
  pull(wate)

tibble(sdo, wate)
```

Once we condition on the observable confounders `age` and `gender`, the weighted average treatment effect is 0.189, which is much smaller than the naive difference in means (0.354) of the treated and untreated groups.


<br>

## Matching

***

### Matching as an estimation strategy
- Idea: we subset the data into "similar" groups based on observed covariates $X_i$. 
- Goal: reduce covariate imbalance between treated and control groups. 
- Estimand: we commonly use ATT, $\E[Y_{1i} - Y_{0i}|X_i, D_i=1]$ (for each treated units, match them with "similar" control units, and discard the rest). Recall that for the treated units, $\tau_i = \underbrace{Y_i}_{\text{observed}} - \underbrace{Y_{0i}}_{\text{unobserved}}$
- Matching in practice (you can really think it as preprocessing you data): 
    + Which observed covariates $X_i$ to use?
    + How many neighbors to match to (one-on-one or one-to-many)? With or without replacement?
    + How to measure the closeness of two units (what distance metric to use)? Options include euclidean distance, Mahalanobis distance, propensity score, etc.
    + Caliper (only keep the good matches)? 
    + Check this [document](https://kosukeimai.github.io/MatchIt/articles/matching-methods.html) from the `MatchIt` package. 
    + Calculate the estimate until you have a happy matched dataset. 

How it works:

```{r, echo=FALSE, out.width='60%'}
knitr::include_graphics("matching.gif")
```
(Credit: Apoorva Lal and Nick Huntington-Klein)

<br>

#### Advantages: 

- **Ho, Imai, King, and Stuart**: Matching as Nonparametric Preprocessing for Reducing Model Dependence in Parametric Causal Inference** ([2007](https://www.cambridge.org/core/journals/political-analysis/article/matching-as-nonparametric-preprocessing-for-reducing-model-dependence-in-parametric-causal-inference/4D7E6D07C9727F5A604E5C9FCCA2DD21)), Fig.1:
 
```{r, echo=FALSE, fig.align='center', fig.width=10, fig.height=5}
library(MatchIt)
library(scales)
load("Ho_et_al_figure_1.Rdata")

## Ho, Imai, King, Stuart (2007): fig.1, Political Analysis
lm.all1 <- lm_robust(y ~ t+x, data=dta)
lm.all2 <- lm_robust(y ~ t+x+I(x^2), data=dta)
temp <- matchit(t ~ x, data=dta)
matched <- match.data(temp)
lm.m1 <- lm_robust(y ~ t+x, data=matched)
lm.m2 <- lm_robust(y ~ t+x+I(x^2), data=matched)

plot.pts <- seq(from=min(dta$x),to=max(dta$x),by=0.1)
plot.pts2 <- seq(from=5, to=24, by=0.1)

par(mar=c(2, 2, 2, 2) + 0.1, cex.lab=0.7, cex.axis=0.5,
    mgp=c(1,0.5,0), cex.main=0.8, cex=1, mfrow=c(1,2), bg="white")
plot(dta$x[dta$t==1],dta$y[dta$t==1],pch="T", col="red",
     xlim=range(dta$x), ylim = range(dta$y),
     xlab="X", ylab = "Y", cex=0.8, main="Before Matching")
points(dta$x[dta$t==0],dta$y[dta$t==0],pch="C", cex=0.8, col="blue")
abline(lm.all1$coef[1] + lm.all1$coef[2], lm.all1$coef[3], lty=1, col="red", lwd=1.5)
abline(lm.all1$coef[1], lm.all1$coef[3], lty=1, col="blue", lwd=1.5)
lines(plot.pts, lm.all2$coef[1] + lm.all2$coef[2] +
     lm.all2$coef[3]*plot.pts + lm.all2$coef[4]*plot.pts^2,
      lty=2, col="red", lwd=1.5)
lines(plot.pts, lm.all2$coef[1] + lm.all2$coef[3]*plot.pts +
      lm.all2$coef[4]*plot.pts^2, lty=2, col="blue", lwd=1.5)
legend(5, 4.75, lty=c(1, 1, 2, 2), col=c(1, 8, 1, 8), lwd=1.5,
               legend=c("Linear Model, Treated Group", "Linear Model, Control Group",
                 "Quadratic Model, Treated Group", "Quadratic Model, Control Group"), cex=0.5)
plot(matched$x[matched$t==1], matched$y[matched$t==1],
     pch="T", xlab="X", ylab="Y", col="red", xlim=range(dta$x),
     ylim=range(dta$y), cex=0.8, main="After Matching")
points(matched$x[matched$t==0], matched$y[matched$t==0], pch="C", cex=0.8, col="blue")
points(dta$x[temp$weights==0 & dta$t==0],
       dta$y[temp$weights==0 & dta$t==0],
       pch="C", col=alpha("blue", 0.4), cex=0.8)
lines(plot.pts2, lm.m1$coef[1] + lm.m1$coef[2] + lm.m1$coef[3]*plot.pts2, lty=1, col="red", lwd=1.5)
lines(plot.pts2, lm.m1$coef[1] + lm.m1$coef[3]*plot.pts2, lty=1, col="blue", lwd=1.5)
lines(plot.pts2, lm.m2$coef[1] + lm.m2$coef[2] +
      lm.m2$coef[3]*plot.pts2 + lm.m2$coef[4]*plot.pts2^2,
      lty=2, col="red", lwd=1.5)
lines(plot.pts2, lm.m2$coef[1] + lm.m2$coef[3]*plot.pts2 +
      lm.m2$coef[4]*plot.pts2^2, lty=2, col="blue", lwd=1.5)
legend(5, 4.75, lty=c(1, 1, 2, 2), col=c(1, 8, 1, 8), lwd=1.5,
       legend=c("Linear Model, Treated Group", "Linear Model, Control Group",
         "Quadratic Model, Treated Group", "Quadratic Model, Control Group"), cex=0.5)
```

- **Reducing model dependence** and **ensuring common support**: without matching, the model we select for the relationship between $X_i$ and $Y_i$ will affect the estimates --- we get different model fit for linear model and quadratic model with $X_i^2$ term, and moreover, the effect estimate has opposite sign (positive to negative). It's mainly due to control units that different from treated units in $X_i$, which would be "pruned" by matching. In other words, matching "balances" observed covariates across treatment groups, i.e., $P(X_i=x|D_i=1) = P(X_i=x|D_i=0, \text{matched})$.

 <br>

#### Disadvantages: 
- Still have residual imbalance. 
- Bias arise with more continuous covariates.
 + Abadie-Imbens (2006) bias adjustment: $$\hat{\tau}_{ATT}  = \frac{1}{N_1} \sum_{D_i=1} [Y_i - Y_{j(i)} - (\hat \mu_0(X_i) - \hat \mu_0(X_{j(i)}))]$$ where $\mu_0(x) = \E[Y|X, D=0]$. In R, use `Match(Y, Tr, X, BiasAdjust = TRUE)`

 <br>

### Matching Coding Example (Exact Match)

Example: Blattman and Annan (2009). We want to investigate the impact of being abducted by the LRA (the treatment; `abd`) on education (outcome variable; `educ`). We can use the newer `MatchIt` package or the older `Matching` package. 

```{r message=FALSE}
library(foreign)
library(MatchIt)
library(Matching)
library(ebal) # entropy balancing
library(cobalt) # love plots
library(knitr)
library(kableExtra)

dat <- read.csv("BlattmanAnnan.csv")
glimpse(dat)

# what is the naive estimated treatment effect? 
summary(lm_robust(educ ~ abd, data = dat)) # -0.6
```

#### Step 1: Check the covariate balance 

```{r}
# keep covariates to use going forward, so we don't have to keep copying them
covariates <- c("age", "fthr_ed", "mthr_ed", "hh_size96", "orphan96", "C_ach",
                "C_akw", "C_ata", "C_kma", "C_oro", "C_pad", "C_paj", "C_pal")

balance_formula <- as.formula(paste("abd ~ ", paste(covariates, collapse=" + ")))

summary(lm_robust(balance_formula, data=dat))
```

We could plot the PDF of each covariate between treatment and control:
```{r, fig.width=6, fig.height=4}
dat %>% dplyr::select(abd, all_of(covariates)) %>%
  mutate(abd = as_factor(ifelse(abd==1, "Treaed", "Control"))) %>% 
  reshape2::melt(all_of(covariates), id.vars = "abd") %>%  #make it long format
  ggplot(aes(x = value)) +
  geom_density(aes(col = as_factor(abd)), alpha = 0.4) +
  facet_wrap(~ variable, scales = "free") +
  labs(title = paste0("PDF of Covariates by Treatment Status"), 
       y = "Density", col = "Treatment") +
  labs(col = "Treatment") +
  theme_minimal() +
  theme(axis.text.y = element_blank(), axis.ticks.y = element_blank())
```

We can also use the `MatchBalance` function from `Matching` and `baltest.collect` from `ebal`:
```{r}
mb <- MatchBalance(balance_formula, data = dat, nboots = 1000, print.level = 0) # set print.level = 0

variable_names = all.vars(balance_formula)[-1] # remove the first variable (abd)
balance_test <- baltest.collect(mb, var.names = covariates, after = FALSE) # use after = FALSE cuz we want to see balance before matching
balance_test <- balance_test[, c("mean.Tr", "mean.Co", "T pval", "KS pval")] # select the columns we want

balance_test %>%
  kable(booktabs = T, digits = 3, align = rep('c', 4),
        col.names = c("Treatment Mean", "Control Mean", "T p-value", "KS p-value")) %>% 
  kable_styling(full_width = F, position = "center")
```

Or we can use the `MatchIt` package: 
```{r}
m.out0 <- matchit(balance_formula, data = dat, method = NULL, distance = "glm")
summary(m.out0)
```

#### Step 2: Matching
Among the covariates we select, `age` and `hh_size96` seems continuous (cannot do exact matching), while the rest are categorical. 

Let's use the `Matching` package: 
```{r}
X <- dat[, covariates]
exact_matches <- ifelse(colnames(X) %in% c("age", "hh_size96"), FALSE, TRUE)

match_model_1 <- Match(Y = dat$educ,
                       Tr = dat$abd,
                       X = X,
                       M = 1, # one-to-one matching
                       exact = exact_matches,
                       estimand = "ATT", 
                       BiasAdjust = TRUE) # bias adjustment

match_model_1$est # ATT
match_model_1$se
```

#### Step 3: Balance After Matching

Again, using `MatchBalance` function from `Matching` and `baltest.collect` from `ebal`:

```{r}
match_balance_after <- MatchBalance(match.out = match_model_1,
                                    formul = balance_formula,
                                    data = dat,
                                    print.level = 0, nboots = 1000)

balance_test_after <- baltest.collect(match_balance_after, var.names = covariates, after = TRUE)
balance_test_after <- balance_test_after[, c("mean.Tr", "mean.Co", "T pval", "KS pval")]

balance_test_after %>%
  kable(booktabs = T, digits = 3, align = rep('c', 4),
        col.names = c("Treatment Mean", "Control Mean", "T p-value", "KS p-value")) %>% 
  kable_styling(full_width = F, position = "center")
```

If the balance does not look good, repeat Step 1-3 again.  

<br>

### Propensity Score

***

- The curse of dimensionality makes it difficult to work in a situation where there are many (pre-treatment) covariates to condition on. Here's a simulation: 
 
```{r, echo=FALSE}
## dataset with 500 obs and 20 covariates
n<-500; n_t<-100; n_c<-n-n_t; p<-20 #100 treated and 400 control
X <- rbind(replicate(p, sample(1:4, size=n_t, replace=TRUE, #treat
                               prob=c(.1, .2, .3, .4))),
           replicate(p, sample(1:4, size=n_c, replace=TRUE))) #control (equal probabilities)
X <- cbind(X, treat=rep(c(1,0), c(n_t, n_c))) #treatment indicator

## How would the plot change with increasing control units, with fixing treat units?
X_2 <- rbind(X, cbind(replicate(p, sample(1:4, size=2000*20-500,
                                          replace=TRUE)), rep(0, 2000)))
X_3 <- rbind(X, cbind(replicate(p, sample(1:4, size=10000*20-500,
                                          replace=TRUE)), rep(0, 10000)))

## make a helper function to get proportion of exact matches
prop_matched <- function(data){
  match_res <- Match(Tr = data[, "treat"], X = data[, 1:(ncol(data)-1)],
                     M = 1, exact = TRUE, replace = TRUE, estimand = "ATT")
  #if no exact match we get FALSE, so assign 0 in that case
  matched <- ifelse(is.logical(match_res)==TRUE, 0, match_res$nobs - match_res$ndrops)
  return(matched/nrow(data))
}

plot_prop_matched <- function(X){
  map_dbl(1:(ncol(X)-1), #without treat indicator column
                            function(d){ prop_matched(X[, c(1:d, 21)]) })
}

plot_df <- tibble(dim=1:20, x1 = plot_prop_matched(X),
                  x2 = plot_prop_matched(X_2), 
                  x3 = plot_prop_matched(X_3)) %>% 
  gather(size, prop, -dim)

ggplot(plot_df, aes(x=dim, y=prop, col=size)) +
  geom_line() +
  labs(title = "Curse of Dimensionality in Matching, with Varying Size",
       x = "Dimensions (# of variables)", y = "Proportion of Exact Matches",
       col = "Control Group Size") +
  scale_color_hue(labels=c("400", "2,000", "10,000")) +
  theme_bw() + theme(legend.position=c(.8,.85))
```

- **Propensity Score**: the probability of treatment conditional on the covariates, or $\pi_i = Pr(D_i=1|X_i)$. Using the propensity score, we can compare units that have a comparable probability of getting treated. In practice, we don’t know the true propensity score --- we usually run a parametric model (like `glm`) to estimate the propensity score. 
 
- Assuming conditional ignorability and common support, we have $\{ Y_{0i}, Y_{1i} \} \independent D_i|\pi_i$, which is called the Balancing Property of the propensity score. Condition on $\pi_i$, $D_i$ does not depend upon $X_i$, thus also no longer depends on $\{ Y_{0i}, Y_{1i} \}$ (SOO). 
 
- After estimating the propensity scores, we can 1) use subclassification or matching, or 2) weight by the inverse of the propensity score.  


###  Matching Coding Example (Propensity Score)

We can use the `Matching` package: 

```{r}
# calculate propensity scores
logit_fit <- glm(balance_formula, data = dat, family = binomial(link = logit))
pi.out <- logit_fit$fitted.values

# plot
ggplot(tibble(ps = pi.out, treatment = as_factor(ifelse(dat$abd==1, "Treated", "Control"))),
       aes(x = ps, col = treatment)) +
  geom_density() +
  labs(title = "Distribution of propensity scores", y = "Density", x = "Propensity Score") +
  xlim(c(0, 1)) +
  theme_minimal()
```

These distributions do not look quite similar. Now let's do the propensity score matching to get more balanced groups. 

```{r}
ps_match <- Match(Y = dat$educ, Tr = dat$abd, X = pi.out, 
                  M = 1, estimand = "ATT")

ps_match_balance <- MatchBalance(match.out = ps_match, formul = balance_formula, data = dat, print.level = 0)

balance_table_ps_match <- baltest.collect(ps_match_balance, var.names = covariates, after = TRUE)
balance_table_ps_match <- balance_table_ps_match[, c("mean.Tr", "mean.Co", "T pval", "KS pval")]

balance_table_ps_match %>% 
  kable(booktabs = T, digits = 3, align = rep('c', 4),
        col.names = c("Treatment Mean", "Control Mean", "T p-value", "KS p-value")) %>% 
  kable_styling(full_width = F, position = "center")
```

Alternatively, we can use the `MatchIt` package (which is a bit more user-friendly). Here's the code to implement the 1-on-1 nearest neighbor matching on the propensity score, with replacement: 

```{r}
m_out_ps <- matchit(balance_formula, data = dat, method = "nearest", distance = "glm", replace = TRUE)
m_out_ps

plot(summary(m_out_ps)) # love plot
```

You can try different Matching specifications. Check this [document](https://kosukeimai.github.io/MatchIt/articles/MatchIt.html#reporting-results) on how to write up the results. 

<br>


## Weighting

***

### Weighting with the Propensity Score

- Matching is good. But it we throw away data (non-matched control units)
- Idea: we can use propensity score as a weight on each observation. 
- Goal: correct for non-random treatment assignment by weighting by the probability of selection into each group.
- **Inverse Probability-of-Treatment Weighting (IPW)**: by reweighting units, we will make a pseudo-population such that the covariates are balanced. Units that do not align with our expectation are weighted up, and units that follow the expected treatment status are weighted down: $$IPW_i = \frac{1}{\Pr(D_i|X_i)} = \frac{1}{D_i \hat{\pi}_i + (1-D_i)(1-\hat{\pi}_i)}$$. 
- IPW estimators are consistent but biased in small samples, and this bias is severe when some weights are extremely large or small. Another option is to use "Stabilized" IPW. which normalizes the weights according to the population distribution: $$SIPW_i = \frac{\Pr(D_i)}{\Pr(D_i|X_i)} = \frac{D_i \Pr(D_i=1) + (1-D_i)(1- \Pr(D_i))}{D_i \hat{\pi}_i + (1-D_i)(1-\hat{\pi}_i)}$$.
- Another issue with weighting is that it is hard to model propensity score $\Rightarrow$ fix: covariate balancing propensity scores (CBPS). 

<br>

### Weighting Coding Example

We can leverage the propensity scores we calculated above. 
```{r}
# use stabilized IPW weights
ps = pi.out # recall that pi.out <- logit_fit$fitted.values
D = dat$abd
PrD = mean(D)
IPW = (D*PrD+(1-D)*(1-PrD))/(D*ps+(1-D)*(1-ps))

# check the propensity scores after weighting
plot(density(ps[D==1], weight = IPW[D==1]/sum(IPW[D==1])), lwd = 2, 
     main="Distribution of propensity scores: Weighted")
lines(density(ps[D==0], weight = IPW[D==0]/sum(IPW[D==0])),lwd = 2, lty = 2)
legend("topleft", legend = c("treated","controls"), lty = c(1, 2), lwd = 2)
```

Now use weights in regression:
```{r}
summary(lm_robust(educ ~ abd, weight = IPW, data = dat))
```

Alternatively, we can use the `WeightIt` package: 

```{r warning=FALSE}
library(WeightIt)

w_out_ps <- weightit(balance_formula, data = dat, method = "glm", estimand = "ATE")
summary(w_out_ps)
```

Then we can estimate the treatment effect:
```{r}
summary(lm_weightit(educ ~ abd, data = dat, weightit = w_out_ps))
```


### Acknowledgement
I develop this document referencing to materials from the previous TAs for PS 200C.

