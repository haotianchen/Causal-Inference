---
title: 'Pol Sci 200C Section: Potential Outcomes and Randomized Experiments'
author: 'Haotian (Barney) Chen'
date: "April 11, 2025"
output:
  html_document:
    math_method: mathjax
    mathjax: "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE)
```
\newcommand{\E}{\mathbb{E}}
\newcommand{\V}{\mathbb{V}}
\newcommand{\independent}{\perp\!\!\!\perp}


## Potential Outcomes

Fundamental concepts: 

* Treatment status: $D_i = 1$ if $i$ is treated, $D_i = 0$ otherwise
* Potential outcome under the treatment condition: $Y_{1i}$
* Potential outcome under the control condition: $Y_{0i}$
* Observed outcome: $Y_i = D_i Y_{1i} + (1-D_i) Y_{0i} = Y_{0i} + (Y_{1i}-Y_{0i})D_i$
* Individual-level treatment effect: $\tau_i = Y_{1i} - Y_{0i}$
* SUTVA: one version of the treatment, no interference between units (unit $i$'s potential outcomes are only a function of its own treatment status, not other units' treatments)

Now let's consider a randomized experiment with six observations and 50\% of the units were randomly assigned to a treatment. The (science) table below shows the data observed from this experiment, augmented with columns for potential outcomes and the individual treatment effect. We fill in all the cells based on the observed information, denoting unknown information with "?". From this table, it is intuitive to see that $D_i$ acts like a **switch** that determines which potential outcome we observe for unit $i$. 

```{r, echo=FALSE, warning=FALSE, message=FALSE}
library(tidyverse)
library(knitr)
library(kableExtra)

tab <- tibble(i = 1:6, Y0 = rep("", 6), Y1 = rep("", 6), Tau = rep("", 6),
             D = c(1, 0, 0, 1, 0, 1), Y = c(8, 2, 4, 6, 12, 10))

tibble(i = 1:6, Y0 = c("?", 2, 4, "?", 12, "?"), Y1 = c(8, "?", "?", 6, "?", 10), Tau = rep("?", 6),
       D = c(1, 0, 0, 1, 0, 1), Y = c(8, 2, 4, 6, 12, 10)) %>%
  kable(booktabs = T, align = rep('c', 6),
        col.names = c("$i$", "$Y_{0i}$", "$Y_{1i}$", "$\\tau_i$", "$D_i$", "$Y_i$")) %>% 
  kable_styling(full_width = F, position = "center", font_size = 15) %>% 
  column_spec(2, color = ifelse(tab[,"D"]==1, "lightgrey", "black")) %>% 
  column_spec(3, color = ifelse(tab[,"D"]==0, "lightgrey", "black")) %>% 
  column_spec(4, color = "lightgrey") %>% 
  add_footnote("counterfactual values are unobserved (grey-colored)")
```
 
**Fundamental problem of causal inference**: there are lots of ?. So, the fundamental problem of causal inference is a big **missing data problem**. The potential outcomes are latent --- the treatment does not change the potential outcomes, it only changes which potential outcomes you see.

<br>

### Average Treatment Effects

Population-wise:

* Average treatment effect (ATE): $\E[Y_{1i}-Y_{0i}] = \E[\tau_i]$
* Average treatment effect among treated (ATT): $\E[Y_{1i}-Y_{0i} | D_i=1] = \E[\tau_i | D_i=1]$
* Average treatment effect among controlled (ATC): $\E[Y_{1i}-Y_{0i} | D_i=0] = \E[\tau_i | D_i=0]$

Now let's assume you are Doctor Strange --- i.e., you can observe what's happening in the multiverses. 

```{r, echo=FALSE, warning=FALSE, message=FALSE}
tab<- tibble(i=1:6, Y0=rep("", 6), Y1=rep("", 6), Tau=rep("", 6),
             D=c(1, 0, 0, 1, 0, 1), Y=c(8, 2, 4, 6, 12, 10))

tibble(i=1:6, Y0=c(6, 2, 4, 1, 12, 3), Y1=c(8, 5, 8, 6, 18, 10), Tau=c(2, 3, 4, 5, 6, 7),
       D=c(1, 0, 0, 1, 0, 1), Y=c(8, 2, 4, 6, 12, 10)) %>%
  kable(booktabs = T, align = rep('c', 6),
        col.names = c("$i$", "$Y_{0i}$", "$Y_{1i}$", "$\\tau_i$", "$D_i$", "$Y_i$")) %>% 
  kable_styling(full_width = F, position = "center", font_size = 15) %>% 
  column_spec(2, color = ifelse(tab[,"D"]==1, "lightgreen", "black")) %>% 
  column_spec(3, color = ifelse(tab[,"D"]==0, "lightgreen", "black")) %>% 
  column_spec(4, color = "lightblue") %>% 
  add_footnote("counterfactual values are magically observed (light-green)")
```

* ATE: (2+3+4+5+6+7)/6 = 4.5
* ATT: (2+5+7)/3 = 4.667
* ATC: (3+4+6)/3 = 4.333

An important and useful trick: we can rewrite the ATE as a weighted average of ATT and ATC. $$\text{ATE} = \text{Pr}(D_i=1)*\text{ATT} + \text{Pr}(D_i=0)*\text{ATC}$$ 

Here you can consider $\text{Pr}(D_i=1)$ as the probability/proportion treated. <span style="color:maroon;">Hint</span>: you will need this equation in Q2, Pset1 --- using the law of iterated expectations. 

<br>

### Naive Difference in Means (DiM)

* Difference in Means (DiM) estimand is: $\E[Y_{i} | D_i =1]-\E[Y_{i} | D_i=0]$ 
* Bias decomposition: DiM = ATT + Bias

$$
\begin{aligned}
\text{DiM} &= \E[Y_{i} | D_i =1]-\E[Y_{i} | D_i=0] \\
&= \E[Y_{1i} | D_i =1]-\E[Y_{0i} | D_i=0] &(\text{consistency; recall Test 1 during lecture})  \\ 
&= \E[Y_{1i} | D_i =1] - \E[Y_{0i} | D_i=1] + \E[Y_{0i} | D_i=1] - \E[Y_{0i} | D_i=0]  & (\text{borrowing } \E[Y_{0i} | D_i=1])\\
&= \text{ATT} + (\E[Y_{0i} | D_i=1] -\E[Y_{0i} | D_i=0])
\end{aligned}
$$

The baseline/selection bias $(\E[Y_{0i} | D_i=1] -\E[Y_{0i} | D_i=0])$ arises when $\E[Y_{0i} | D_i=1] \neq  \E[Y_{0i} | D_i=0]$. Sometimes it's called a "selection into treatment" problem. 

<span style="color:maroon;">Hint</span> for Pset1 Q2: we can repeat the similar decomposition steps for ATC --- think about what term to borrow (add and then remove) to construct the ATC. 


<br>

***

## Identification and Estimation in Randomized Experiments

> - **Identification**: if you can observe data from an entire population, can you learn about your quantity of interest?
- **Estimation**: given your finite amount of data on a sample, how well can you learn about your quantity of interest?

Recall that random assignment guarantees **ignorability**: $$\{Y_{1i}, Y_{0i}\} \independent D_i$$ (a.k.a. "exogeneity", "exchangeability", "unconfoundedness", "no unmeasured confounder", "no omitted variable", etc.): the potential outcomes are independent of the treatments, or treatment status $D_i$ conveys no information whatsoever about the potential values of $Y_{1i}, Y_{0i}$. It makes the treated and untreated units identical in terms of potential outcomes on average; the treatment group and control group are "exchangeable"; the two groups are "balanced" on observables and unobservables. This is the identification assumption our life will depend upon. 

Let's go back to the 6 units example and define the (population) average treatment effect for the treated ($\tau_{ATT}$) and propose an unbiased estimator for this estimand. The estimand is $\tau_{ATT} = \E[Y_{1i} - Y_{0i}|D_i=1]$. Given randomization of treatment, an unbiased estimator is the **difference-in-means** for the treated and control, here's why:

- From ignorability, we have
  $\E[Y_{1i}] = \E[Y_{1i}|D_i=1] = \E[Y_{1i}|D_i=0]$ and $\E[Y_{0i}] = \E[Y_{0i}|D_i=1] = \E[Y_{0i}|D_i=0]$
- In this case, **ATE=ATT**, as follows:

$$
  \begin{aligned}
  \tau_{ATT} &= \E[Y_{1i}-Y_{0i}|D_i=1] = \E[Y_{1i}|D_i=1] - \E[Y_{0i}|D_i=1] & (\text{linearity of expectation})\\
  &= \E[Y_{1i}] - \E[Y_{0i}]   & (\text{ignorability}) \\
  &= \E[Y_{1i} - Y_{0i}] = \tau_{ATE}
  \end{aligned}
$$

- This estimator is **difference-in-means**: $$\hat{\tau}_{ATE} = \underbrace{\frac{1}{N_1}\sum_{i=1}^{n}D_iY_i}_{\text{average among treated}} - \underbrace{\frac{1}{N_0}\sum_{i=1}^{n}(1-D_i)Y_i}_{\text{average among control}}$$
where $N_1$ is the number of treated units and $N_0$ is the number of untreated units.


```{r, warning=FALSE, message=FALSE}
# DiM estimator
tab %>% summarize(dim = mean(Y[D == 1]) - mean(Y[D == 0]))
```

- Under treatment independence, the DiM is an unbiased estimator for the ATE.
 
**Example: Classical Randomized Experiment (with the assumption of ignorability)**
 
a) Identification of **ATE** with Difference-in-Means estimator
$$
  \begin{aligned}
  \tau_{ATE} &\equiv \E[Y_{1i}-Y_{0i}] = \E[Y_{1i}] - \E[Y_{0i}] & (\text{linearity of expectation}) \\
  &= \color{red}{\E[Y_{1i}|D_i=1] - \E[Y_{0i}|D_i=0]}   & (\text{ignorability:}\{y_{1i}, y_{0i}\} \independent D_i) \\
  &= \E[Y_{i}|D_i=1] - \E[Y_{i}|D_i=0] & (\text{consistency, SUTVA}) \\
  &= \frac{1}{n_1}\sum_{i=1}^{n}D_iY_i - \frac{1}{n_0}\sum_{i=1}^{n}(1-D_i)Y_i = \text{DiM}
  \end{aligned}
$$
- We needed ignorability ($\{y_{1i}, y_{0i}\} \independent D_i$), consistency ($Y_{di}=Y_i|D_i=d$), and  SUTVA (no interference and one-version-of-treatment) assumptions for our identification.
 
 <br>
 
b) Identification of **ATT** with Difference-in-Means estimator
$$
\begin{aligned}
 \tau_{ATT} &\equiv \E[Y_{1i} - Y_{0i}|D_i=1] = \E[Y_{1i}|D_i=1] - \E[Y_{0i}|D_i=1]  &\text{(linearity of expectation)} \\
 &= \color{red}{\E[Y_{1i}|D_i=1] - \E[Y_{0i}|D_i=0]}  &\text{(a weaker ignorability: }Y_{0i} \independent D_i) \\
 &= \E[Y_{i}|D_i=1] - \E[Y_{i}|D_i=0] &\text{(consistency, SUTVA)} \\
 &= \text{DiM}
 \end{aligned}
$$

- We needed a weaker version of ignorability assumption to identify the ATT: $Y_{0i} \independent D_i$.
 
 <br>
 
c) Identification of **ATC** with Difference-in-Means estimator
$$
 \begin{aligned}
 \tau_{ATC} &\equiv \E[Y_{1i} - Y_{0i}|D_i=0] = \E[Y_{1i}|D_i=0] - \E[Y_{0i}|D_i=0]  &\text{(linearity of expectation)} \\
 &= \color{red}{\E[Y_{1i}|D_i=1] - \E[Y_{0i}|D_i=0]}  &\text{(a weaker ignorability: }Y_{1i} \independent D_i) \\
 &= \E[Y_{i}|D_i=1] - \E[Y_{i}|D_i=0]   &\text{(consistency, SUTVA)} \\
 &= \text{DiM}
 \end{aligned}
$$

- We needed a weaker version of ignorability assumption to identify the ATT: $Y_{1i} \independent D_i$.
 
  <br>
  
d) The ATE can be expressed as a regression coefficient:
$$
 \begin{aligned}
 Y_i &= D_i Y_{1i} + (1-D_i) Y_{0i} \\
 &= Y_{0i} + (Y_{1i}-Y_{0i})D_i \\
 &= \bar Y_0 + (\bar Y_1-\bar Y_0) D_i + \{(Y_{0i} - \bar Y_0) + D_i[(Y_{1i}-Y_{0i}) - (\bar Y_1-\bar Y_0)]\} \\
 &= \underbrace{\bar Y_0}_{\alpha} + \underbrace{\tau_{ATE}}_{\beta} D_i + \underbrace{[(Y_{0i} - \bar Y_0) + D_i(\tau_i - \tau_{ATE})]}_{\epsilon_i}
 \end{aligned}
$$
  
- Under random assignment, the regression gives us an unbiased estimate of the ATE.

***

## Randomization Inference (RI)

### Uncertainty and Hypothesis Testing

- SATE v. PATE: inference on PATE is harder than on SATE, because we have to account for sampling variation, on top of the variation induced by the treatment D. If the sampling is random, $\E[\text{SATE}] = \text{PATE}$. 
- A (conservative --- proof in lecture slides!) SE estimator (Neyman estimator) is $$\widehat{SE}_{ATE} = \sqrt{\frac{\hat{\sigma}^2_{Y_1}}{N_1} + \frac{\hat{\sigma}^2_{Y_0}}{N_0}}$$ It relies on the expectation that $\text{cov}(\bar Y_1, \bar Y_0) = 0$. 
- The two-sample t-test with unequal variances is then: $$t = \frac{\hat{\tau}_{ATE}}{\sqrt{\frac{\hat{\sigma}^2_{Y_1}}{N_1} + \frac{\hat{\sigma}^2_{Y_0}}{N_0}}}$$ where $N_1$ and $N_0$ are the number of treated units and control units. We know that $t \overset{d}{\rightarrow} N(0,1)$ for large $n$. 
- We can then construct the 95\% CI: $\hat{\tau}_{\text{ATE}} \pm 1.96 * {\widehat{\text{SE}}}_{\widehat{\text{ATE}}}$.

Putting them into pseudocodes: suppose we have treated and control from data (<span style="color:maroon;">Hint</span>: this relates to Pset1, Q3)

```{r eval=FALSE}
DIM = mean(treated) - mean(control) #\hat ATE
SE = sqrt(var(treated) / length(treated) + var(control) / length(control))
t_statistic = DIM / SE
CI = (DIM - 1.96*SE, DIM + 1.96*SE)

# can we reject the null? 
abs(t_statistic) > 1.96
```

### The Idea of Randomization Inference
- **(Weak) null**: $H_0: \tau_{ATE} = 0$.
- **Sharp null**: $H_0: Y_{1i} = Y_{0i}$.
- Randomization inference (RI) poses sharp null, under which we can fill in all the potential outcomes and can compute the ATE under each possible treatment assignment. Then we can compute the sampling distribution of the test statistic under the sharp null and make inference.


### RI with small data: Fisher's exact test

1) Calculate the test statistic (e.g., DiM) under the observed treatment assignment. In our case, it is $\hat{\tau}_{\text{ATE}}$.
2) Specify the sharp null hypothesis: $H_0: \tau_i=\tau_0$, where $\tau_0$ is any constant. We typically set $\tau_0=0$. Then fill in missing potential outcomes under the sharp null: replace all the unobserved potential outcomes with revealed outcome $\pm \tau_0$.
3) Obtain every possible treatment assignment vector $\omega \in \Omega$, by the permutation of original treatment assignment vector.
4) Calculate the test statistic under each $\omega$ (don't forget to make each assignment "turn on" the observed outcome) to get the null distribution $\hat{\tau}(\omega)$s. How extreme is the observed test statistic compared to the null distribution?

Here's an example of how to do this in R: 

```{r}
# Data from Table 2-1, Gerber and Green, "Field Experiments" (2012)
tiny_data <- tibble(i = 1:7, # unit index
                      Y0 = c(10, 15, 20, 20, 10, 15, 15), # untreated potential outcomes
                      Y1 = c(15, 15, 30, 15, 20, 15, 30), # treated potential outcomes
                      tau = Y1-Y0) %>% # individual treatment effect
  mutate(D = c(1, 0, 0, 0, 0, 0, 1)) %>% # one possible treatment assignment
  mutate(Y = if_else(D == 1, Y1, Y0)) # observed outcome: Y = D*Y1 + (1-D)*Y0
```

```{r, echo=FALSE}
tiny_data %>%  #science table
  kable(booktabs = T, digits=3, align = rep('c', 6),
        col.names = c("$i$", "$Y_{0i}$", "$Y_{1i}$", "$\\tau_i$", "$D_i$", "$Y_i$")) %>% 
  kable_styling(full_width = F, position = "center", font_size = 15) %>%
  column_spec(2, color = ifelse(tiny_data[,"D"]==1, "lightgrey", "black")) %>% 
  column_spec(3, color = ifelse(tiny_data[,"D"]==0, "lightgrey", "black")) %>% 
  column_spec(4, color = "lightgrey") %>% 
  add_footnote("counterfactual values are unobserved (grey-colored)")
```

##### Step 1:
```{r}
# observed treatment assignment
tiny_data$D # `\omega_obs`

# observed ate estimate
obs_dim <- tiny_data %>% summarize(estimate = mean(Y[D==1]) - mean(Y[D==0])) %>% pull(estimate)
obs_dim
```

##### Step 2:
```{r}
# fix potential outcomes implied by sharp null tau_i = tau_0
tau_0 <- 0

# fill in potential outcomes under sharp null
tiny_data <- tiny_data %>%
  mutate(Y0_sn = Y, Y1_sn = Y) %>%
  mutate(Y0_sn = ifelse(D==1, Y1_sn - tau_0, Y0_sn),
         Y1_sn = ifelse(D==0, Y0_sn + tau_0, Y1_sn))
```

##### Step 3:
We'll use complete randomization: exactly 2 units are treated. The probability of receiving treatment for each unit is $\Pr(D_i)=2/7$. For $\Omega$, since we choose 2 treated units from 7, there are 21 possible assignments (${7 \choose 2}=21$) in total.

```{r}
Omega <- combn(length(tiny_data$D), sum(tiny_data$D), tabulate, nbins = length(tiny_data$D)) %>% 
  as_tibble()
Omega # the 6th is the observed one
```

##### Step 4:
```{r}
# make a function for RI
ri_exact <- function(data, permutations, c){
  data %>% 
    mutate(D_sim = permutations[, c]) %>% # c is the column index for which assignment
    mutate(Y_sim = ifelse(D==1, Y1_sn, Y0_sn)) %>% 
    summarize(dim = mean(Y_sim[D_sim==1]) - mean(Y_sim[D_sim==0])) %>% pull()
}

# get the null distribution 
exact_dist <- map_dbl(1:ncol(Omega), function(c) ri_exact(tiny_data, Omega, c))
exact_dist
```

Now, $$p \equiv \Pr(|\hat{\tau}(\omega)| \geq |\hat{\tau}_{\text{ATE}}|)$$

```{r}
mean(abs(exact_dist) >= abs(obs_dim)) # p-value
```


### RI with large data
The randomization inference can be conducted in large sample. The key idea is the same as the exact test: under the sharp null, we can fill in all potential outcomes. Since the number of possible treatment assignment gets too large when $n$ is large, exact computation is almost impossible. One way to get around this is to use Monte Carlo simulations to get the sampling distribution of the test statistic. 

1) Calculate the test statistic (e.g., DiM) under the observed treatment assignment ($\hat{\tau}_{\text{ATE}}$).
2) Specify the sharp null hypothesis: $H_0: \tau_i=\tau_0$ and fill in missing potential outcomes under the sharp null: replace all the unobserved potential outcomes with revealed outcome $\pm \tau_0$.
3) Sample another assignment vector $\omega_i$ according to the original randomization procedure: simple random assignment or reshuffle the treatment vector (complete randomization case). Also update observed outcomes $Y_i$ according to simulated assignment.
4) Calculate the test statistic under $\omega_i$. In our case, compute the DiM estimate.
5) Repeat steps (3) and (4) many many times get the null distribution $\hat{\tau}(\omega_i)$s and make inference.


Here's an example of how to do this in R. <span style="color:maroon;">Hint</span>: this code chunk relates to Q4, Pset1.

```{r}
set.seed(2025)

n <- 1000
large_sample <- tibble(i = 1:n,
                       Y0 = rnorm(n),
                       Y1 = Y0 + rnorm(n, .1, .05),
                       tau = Y1-Y0) %>%
  # let's do a simple random assignment
  mutate(D = sample(c(0, 1), n, replace = TRUE, prob = c(.5, .5))) %>%
  mutate(Y = if_else(D==1, Y1, Y0))
```

Here's the first ten rows of the simulated data: 

```{r, echo=FALSE}
large_sample[1:10,] %>%  #display first 10 units only
  kable(booktabs = T, digits=3, align = rep('c', 6),
        col.names = c("$i$", "$Y_{0i}$", "$Y_{1i}$", "$\\tau_i$", "$D_i$", "$Y_i$")) %>% 
  kable_styling(full_width = F, position = "center", font_size = 15) %>%
  column_spec(2, color = ifelse(large_sample[1:10,"D"]==1, "lightgrey", "black")) %>% 
  column_spec(3, color = ifelse(large_sample[1:10,"D"]==0, "lightgrey", "black")) %>% 
  column_spec(4, color = "lightgrey") %>% 
  add_footnote("counterfactual values are unobserved (grey-colored)")
```

```{r, fig.align='center'}
## Monte Carlo approximation for randomization inference

ri_function <- function(Y, D, M){
  obs_dim <- mean(Y[D==1]) - mean(Y[D==0])
  Y0_sn = Y
  Y1_sn = Y # you may want to handle NA here
  
  res <- map_dbl(1:M, function(empty_input){
    new_assignment <- sample(D, length(D), replace = FALSE)
    new_dim <- mean(Y1_sn[new_assignment==1]) - mean(Y0_sn[new_assignment==0])
    return(new_dim)
  })
  
  # RI p-value (2-sided)
  p_value = sum(abs(res) >= abs(obs_dim))/length(res)
  
  return(list(simulation_dt = res,
              obs_dim = obs_dim,
              p_value = p_value))
}

ir_result <- ri_function(large_sample$Y, large_sample$D, 100)
ir_result$p_value

# make a plot
plot(density(ir_result$simulation_dt), main = "Null Distribution for DiM")
abline(v = ir_result$obs_dim, col="darkblue")
```

<br>

**Final Remark**: what if you have a more complex design (or you don't want to write your own function)? You can use the `ri2` package. Check this quick [manual](https://cran.r-project.org/web/packages/ri2/vignettes/ri2_vignette.html) by Alexander Coppock. 


***

## Extra: When To Use (Pre-treat) Covariates in Randomized Experiments

### Check Covariate Balance

Even if you have a complete randomized experiment, you may want to check the balance of covariates. Why (or why not)? <span style="color:maroon;">Hint</span>: this relates to Q3, Pset1. 

```{r warning=FALSE, message=FALSE}
library(Matching) # assess balance 
library(ebal) # making table

data(lalonde)
glimpse(lalonde)

balance_obj = MatchBalance(treat ~ age + educ + black + hisp,
                           data = lalonde,
                           print.level = 0)

table_bal = baltest.collect(balance_obj,
                            var.names = c("age", "education", 
                                          "black", "hispanic"),
                            after = FALSE) # give us the pre-matching balance

table_bal = table_bal[, c(1, 2, 6, 7)] # select things we care

# mean.Tr, mean.Co <-- treatment and control means
# T pval, KS pval <-- p-values for t-test difference in means and KS test

knitr::kable(table_bal, digits = 4) %>% kable_styling()
```

<br>

### Block (or stratified) Randomized Experiment
In a block randomized experiment design, you first divide the sample into some mutually-exclusive blocks (or strata) based on some covariates. Then, you do a complete randomly assignment within each block. Finally, you aggregate the estimates to a weighted average by block size.  

```{r}
library(randomizr)   # random assignment
library(fabricatr)   # data simulation
library(estimatr)    

set.seed(2025)

block_data <- fabricate(
  N = 1000,
  Y = rnorm(N),
  blockID = sample(letters[1:10], size = N, replace = TRUE),
  treat = block_ra(blocks = blockID))

head(block_data, 15)

tidy(lm_robust(Y ~ treat, data = block_data, fixed_effects = blockID))
```

<br>

### Clustered Randomized Experiment
In a clustered randomized experiment design, you randomly assign treatment at the cluster level (e.g., schools) rather than at the individual level. 

```{r}
cluster_data <- fabricate(
  N = 1000,
  Y = rnorm(N),
  clusterID = sample(letters[1:10], size = N, replace = TRUE),
  treat = cluster_ra(clusterID))

head(cluster_data, 15)

tidy(lm_robust(Y ~ treat, data = cluster_data, clusters = clusterID, se_type = "CR2"))
```


***

## Extra Homework Hints

### Heteroskedasticity-consistent SEs

We have already covered the concepts in last week's refersher but here is a quick recap of how to do it in R. <span style="color:maroon;">Hint</span>: this relates to Q3, Pset1. 

```{r warning=FALSE, message=FALSE}
set.seed(2025)

X <- cbind(1, rnorm(100), runif(100, 0, 10))
epsilon <- rnorm(100)
true_beta = c(1, 2, 3)
Y <- X %*% true_beta + epsilon

lm_res <- lm(Y ~ X-1)

#1. Using the `sandwich` package
library(sandwich)
library(lmtest)
coeftest(lm_res, vcov = vcovHC(lm_res, type = "HC2")) # we choose "HC2"

#2. Using the `estimatr` package
library(estimatr)
lm_robust(Y ~ X-1, se_type = "HC2")
```


### Acknowledgement
I develop this document based on materials from the previous TAs for PS 200C (including Doeun Kim,  Soonhong Cho, Luke Sonnet, Aaron Rudkin, Ciara Sterbenz).
